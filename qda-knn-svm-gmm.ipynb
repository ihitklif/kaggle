{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.csv', 'sample_submission.csv', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>muggy-smalt-axolotl-pembus</th>\n",
       "      <th>dorky-peach-sheepdog-ordinal</th>\n",
       "      <th>slimy-seashell-cassowary-goose</th>\n",
       "      <th>snazzy-harlequin-chicken-distraction</th>\n",
       "      <th>frumpy-smalt-mau-ordinal</th>\n",
       "      <th>stealthy-beige-pinscher-golden</th>\n",
       "      <th>chummy-cream-tarantula-entropy</th>\n",
       "      <th>hazy-emerald-cuttlefish-unsorted</th>\n",
       "      <th>nerdy-indigo-wolfhound-sorted</th>\n",
       "      <th>leaky-amaranth-lizard-sorted</th>\n",
       "      <th>ugly-tangerine-chihuahua-important</th>\n",
       "      <th>shaggy-silver-indri-fimbus</th>\n",
       "      <th>flaky-chocolate-beetle-grandmaster</th>\n",
       "      <th>squirrely-harlequin-sheep-sumble</th>\n",
       "      <th>freaky-tan-angelfish-noise</th>\n",
       "      <th>lousy-plum-penguin-sumble</th>\n",
       "      <th>bluesy-rose-wallaby-discard</th>\n",
       "      <th>baggy-copper-oriole-dummy</th>\n",
       "      <th>stealthy-scarlet-hound-fepid</th>\n",
       "      <th>greasy-cinnamon-bonobo-contributor</th>\n",
       "      <th>cranky-cardinal-dogfish-ordinal</th>\n",
       "      <th>snippy-auburn-vole-learn</th>\n",
       "      <th>greasy-sepia-coral-dataset</th>\n",
       "      <th>flabby-tangerine-fowl-entropy</th>\n",
       "      <th>lousy-smalt-pinscher-dummy</th>\n",
       "      <th>bluesy-brass-chihuahua-distraction</th>\n",
       "      <th>goopy-eggplant-indri-entropy</th>\n",
       "      <th>homey-sepia-bombay-sorted</th>\n",
       "      <th>homely-ruby-bulldog-entropy</th>\n",
       "      <th>hasty-blue-sheep-contributor</th>\n",
       "      <th>blurry-wisteria-oyster-master</th>\n",
       "      <th>snoopy-auburn-dogfish-expert</th>\n",
       "      <th>stinky-maroon-blue-kernel</th>\n",
       "      <th>bumpy-amaranth-armadillo-important</th>\n",
       "      <th>slaphappy-peach-oyster-master</th>\n",
       "      <th>dorky-tomato-ragdoll-dataset</th>\n",
       "      <th>messy-mauve-wolverine-ordinal</th>\n",
       "      <th>geeky-pumpkin-moorhen-important</th>\n",
       "      <th>crabby-teal-otter-unsorted</th>\n",
       "      <th>...</th>\n",
       "      <th>beady-mauve-frog-distraction</th>\n",
       "      <th>surly-brass-maltese-ordinal</th>\n",
       "      <th>beady-asparagus-opossum-expert</th>\n",
       "      <th>beady-rust-impala-dummy</th>\n",
       "      <th>droopy-amethyst-dachshund-hint</th>\n",
       "      <th>homey-crimson-budgerigar-grandmaster</th>\n",
       "      <th>droopy-cardinal-impala-important</th>\n",
       "      <th>woozy-apricot-moose-hint</th>\n",
       "      <th>paltry-sapphire-labradoodle-dummy</th>\n",
       "      <th>crappy-carmine-eagle-entropy</th>\n",
       "      <th>greasy-magnolia-spider-grandmaster</th>\n",
       "      <th>crabby-carmine-flounder-sorted</th>\n",
       "      <th>skimpy-copper-fowl-grandmaster</th>\n",
       "      <th>hasty-seashell-woodpecker-hint</th>\n",
       "      <th>snappy-purple-bobcat-important</th>\n",
       "      <th>thirsty-carmine-corgi-ordinal</th>\n",
       "      <th>homely-auburn-reindeer-unsorted</th>\n",
       "      <th>crappy-beige-tiger-fepid</th>\n",
       "      <th>cranky-auburn-swan-novice</th>\n",
       "      <th>chewy-bistre-buzzard-expert</th>\n",
       "      <th>skinny-cyan-macaque-pembus</th>\n",
       "      <th>slimy-periwinkle-otter-expert</th>\n",
       "      <th>snazzy-burgundy-clam-novice</th>\n",
       "      <th>cozy-ochre-gorilla-gaussian</th>\n",
       "      <th>homey-sangria-wolfhound-dummy</th>\n",
       "      <th>snazzy-asparagus-hippopotamus-contributor</th>\n",
       "      <th>paltry-red-hamster-sorted</th>\n",
       "      <th>zippy-dandelion-insect-golden</th>\n",
       "      <th>baggy-coral-bandicoot-unsorted</th>\n",
       "      <th>goopy-lavender-wolverine-fimbus</th>\n",
       "      <th>wheezy-myrtle-mandrill-entropy</th>\n",
       "      <th>wiggy-lilac-lemming-sorted</th>\n",
       "      <th>gloppy-cerise-snail-contributor</th>\n",
       "      <th>woozy-silver-havanese-gaussian</th>\n",
       "      <th>jumpy-thistle-discus-sorted</th>\n",
       "      <th>muggy-turquoise-donkey-important</th>\n",
       "      <th>blurry-buff-hyena-entropy</th>\n",
       "      <th>bluesy-chocolate-kudu-fepid</th>\n",
       "      <th>gamy-white-monster-expert</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>707b395ecdcbb4dc2eabea00e4d1b179</td>\n",
       "      <td>-2.070654</td>\n",
       "      <td>1.018160</td>\n",
       "      <td>0.228643</td>\n",
       "      <td>0.857221</td>\n",
       "      <td>0.052271</td>\n",
       "      <td>0.230303</td>\n",
       "      <td>-6.385090</td>\n",
       "      <td>0.439369</td>\n",
       "      <td>-0.721946</td>\n",
       "      <td>-0.227027</td>\n",
       "      <td>0.575964</td>\n",
       "      <td>1.541908</td>\n",
       "      <td>1.745286</td>\n",
       "      <td>-0.624271</td>\n",
       "      <td>3.600958</td>\n",
       "      <td>1.176489</td>\n",
       "      <td>-0.182776</td>\n",
       "      <td>-0.228391</td>\n",
       "      <td>1.682263</td>\n",
       "      <td>-0.833236</td>\n",
       "      <td>-4.377688</td>\n",
       "      <td>-5.372410</td>\n",
       "      <td>-0.477742</td>\n",
       "      <td>-0.179005</td>\n",
       "      <td>-0.516475</td>\n",
       "      <td>0.127391</td>\n",
       "      <td>-0.857591</td>\n",
       "      <td>-0.461500</td>\n",
       "      <td>2.160303</td>\n",
       "      <td>-2.118371</td>\n",
       "      <td>0.515493</td>\n",
       "      <td>-1.201493</td>\n",
       "      <td>-0.027377</td>\n",
       "      <td>-1.154024</td>\n",
       "      <td>0.753204</td>\n",
       "      <td>-0.179651</td>\n",
       "      <td>-0.807341</td>\n",
       "      <td>-1.663626</td>\n",
       "      <td>0.893806</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.829848</td>\n",
       "      <td>2.347131</td>\n",
       "      <td>0.082462</td>\n",
       "      <td>-1.012654</td>\n",
       "      <td>0.593752</td>\n",
       "      <td>2.904654</td>\n",
       "      <td>-0.428974</td>\n",
       "      <td>-0.919979</td>\n",
       "      <td>2.849575</td>\n",
       "      <td>-0.906744</td>\n",
       "      <td>0.729459</td>\n",
       "      <td>0.386140</td>\n",
       "      <td>0.319814</td>\n",
       "      <td>-0.407682</td>\n",
       "      <td>-0.170667</td>\n",
       "      <td>-1.242919</td>\n",
       "      <td>-1.719046</td>\n",
       "      <td>-0.132395</td>\n",
       "      <td>-0.368991</td>\n",
       "      <td>-5.112553</td>\n",
       "      <td>-2.085988</td>\n",
       "      <td>-0.897257</td>\n",
       "      <td>1.080671</td>\n",
       "      <td>-0.273262</td>\n",
       "      <td>0.342824</td>\n",
       "      <td>0.640177</td>\n",
       "      <td>-0.415298</td>\n",
       "      <td>-0.483126</td>\n",
       "      <td>-0.080799</td>\n",
       "      <td>2.416224</td>\n",
       "      <td>0.351895</td>\n",
       "      <td>0.618824</td>\n",
       "      <td>-1.542423</td>\n",
       "      <td>0.598175</td>\n",
       "      <td>0.611757</td>\n",
       "      <td>0.678772</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>-0.806677</td>\n",
       "      <td>-0.193649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5880c03c6582a7b42248668e56b4bdec</td>\n",
       "      <td>-0.491702</td>\n",
       "      <td>0.082645</td>\n",
       "      <td>-0.011193</td>\n",
       "      <td>1.071266</td>\n",
       "      <td>-0.346347</td>\n",
       "      <td>-0.082209</td>\n",
       "      <td>0.110579</td>\n",
       "      <td>-0.382374</td>\n",
       "      <td>-0.229620</td>\n",
       "      <td>0.783980</td>\n",
       "      <td>-1.280579</td>\n",
       "      <td>-1.003480</td>\n",
       "      <td>-7.753201</td>\n",
       "      <td>-1.320547</td>\n",
       "      <td>0.919078</td>\n",
       "      <td>-1.036068</td>\n",
       "      <td>0.030213</td>\n",
       "      <td>0.910172</td>\n",
       "      <td>-0.905345</td>\n",
       "      <td>0.646641</td>\n",
       "      <td>-0.465291</td>\n",
       "      <td>-0.531735</td>\n",
       "      <td>-0.756781</td>\n",
       "      <td>0.193724</td>\n",
       "      <td>0.224277</td>\n",
       "      <td>-0.474412</td>\n",
       "      <td>1.885805</td>\n",
       "      <td>0.205439</td>\n",
       "      <td>-6.481422</td>\n",
       "      <td>1.035620</td>\n",
       "      <td>-0.453623</td>\n",
       "      <td>0.375936</td>\n",
       "      <td>-0.320670</td>\n",
       "      <td>-0.144646</td>\n",
       "      <td>-0.220129</td>\n",
       "      <td>0.577826</td>\n",
       "      <td>-0.360512</td>\n",
       "      <td>-0.600107</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982205</td>\n",
       "      <td>-1.161978</td>\n",
       "      <td>0.532269</td>\n",
       "      <td>1.133215</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>-1.390962</td>\n",
       "      <td>0.158572</td>\n",
       "      <td>0.143794</td>\n",
       "      <td>-0.317185</td>\n",
       "      <td>1.017192</td>\n",
       "      <td>-0.395342</td>\n",
       "      <td>-0.642357</td>\n",
       "      <td>-0.627209</td>\n",
       "      <td>0.257271</td>\n",
       "      <td>-1.461564</td>\n",
       "      <td>0.325613</td>\n",
       "      <td>1.628369</td>\n",
       "      <td>0.640040</td>\n",
       "      <td>0.750735</td>\n",
       "      <td>1.164573</td>\n",
       "      <td>0.900373</td>\n",
       "      <td>0.063489</td>\n",
       "      <td>0.948158</td>\n",
       "      <td>0.273014</td>\n",
       "      <td>-1.269147</td>\n",
       "      <td>-0.251101</td>\n",
       "      <td>-2.271731</td>\n",
       "      <td>-0.044167</td>\n",
       "      <td>-0.443766</td>\n",
       "      <td>-1.144794</td>\n",
       "      <td>-0.645115</td>\n",
       "      <td>-1.246090</td>\n",
       "      <td>2.613357</td>\n",
       "      <td>-0.479664</td>\n",
       "      <td>1.581289</td>\n",
       "      <td>0.931258</td>\n",
       "      <td>0.151937</td>\n",
       "      <td>-0.766595</td>\n",
       "      <td>0.474351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4ccbcb3d13e5072ff1d9c61afe2c4f77</td>\n",
       "      <td>-1.680473</td>\n",
       "      <td>0.860529</td>\n",
       "      <td>-1.076195</td>\n",
       "      <td>0.740124</td>\n",
       "      <td>3.678445</td>\n",
       "      <td>0.288558</td>\n",
       "      <td>0.515875</td>\n",
       "      <td>0.920590</td>\n",
       "      <td>-1.223277</td>\n",
       "      <td>-1.029780</td>\n",
       "      <td>-2.203397</td>\n",
       "      <td>-7.088717</td>\n",
       "      <td>0.438218</td>\n",
       "      <td>-0.848173</td>\n",
       "      <td>1.542666</td>\n",
       "      <td>-2.166858</td>\n",
       "      <td>-0.867670</td>\n",
       "      <td>-0.980947</td>\n",
       "      <td>0.567793</td>\n",
       "      <td>1.323430</td>\n",
       "      <td>-2.076700</td>\n",
       "      <td>-0.291598</td>\n",
       "      <td>-1.564816</td>\n",
       "      <td>-8.718695</td>\n",
       "      <td>0.340144</td>\n",
       "      <td>-0.566402</td>\n",
       "      <td>0.844324</td>\n",
       "      <td>0.816421</td>\n",
       "      <td>-1.019114</td>\n",
       "      <td>-0.881431</td>\n",
       "      <td>-2.285710</td>\n",
       "      <td>-0.090958</td>\n",
       "      <td>-0.898440</td>\n",
       "      <td>-0.584417</td>\n",
       "      <td>-0.143660</td>\n",
       "      <td>-0.182084</td>\n",
       "      <td>0.798516</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>-0.347155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829467</td>\n",
       "      <td>0.588236</td>\n",
       "      <td>0.427946</td>\n",
       "      <td>-0.563037</td>\n",
       "      <td>-0.103990</td>\n",
       "      <td>-0.817698</td>\n",
       "      <td>1.251046</td>\n",
       "      <td>-0.977157</td>\n",
       "      <td>2.732600</td>\n",
       "      <td>1.997984</td>\n",
       "      <td>-0.214285</td>\n",
       "      <td>-0.389428</td>\n",
       "      <td>-1.007633</td>\n",
       "      <td>0.336435</td>\n",
       "      <td>-0.851292</td>\n",
       "      <td>-0.024184</td>\n",
       "      <td>0.455908</td>\n",
       "      <td>0.458753</td>\n",
       "      <td>-0.267230</td>\n",
       "      <td>-2.032402</td>\n",
       "      <td>0.203082</td>\n",
       "      <td>0.654107</td>\n",
       "      <td>-3.512338</td>\n",
       "      <td>-0.840937</td>\n",
       "      <td>0.519407</td>\n",
       "      <td>-0.028053</td>\n",
       "      <td>-1.621083</td>\n",
       "      <td>0.142132</td>\n",
       "      <td>1.514664</td>\n",
       "      <td>0.828815</td>\n",
       "      <td>0.516422</td>\n",
       "      <td>0.130521</td>\n",
       "      <td>-0.459210</td>\n",
       "      <td>2.028205</td>\n",
       "      <td>-0.093968</td>\n",
       "      <td>-0.218274</td>\n",
       "      <td>-0.163136</td>\n",
       "      <td>-0.870289</td>\n",
       "      <td>0.064038</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e350f17a357f12a1941f0837afb7eb8d</td>\n",
       "      <td>0.183774</td>\n",
       "      <td>0.919134</td>\n",
       "      <td>-0.946958</td>\n",
       "      <td>0.918492</td>\n",
       "      <td>0.862278</td>\n",
       "      <td>1.155287</td>\n",
       "      <td>0.911106</td>\n",
       "      <td>0.562598</td>\n",
       "      <td>-1.349685</td>\n",
       "      <td>-1.182729</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>-0.626847</td>\n",
       "      <td>0.368980</td>\n",
       "      <td>1.560784</td>\n",
       "      <td>0.502851</td>\n",
       "      <td>-0.108050</td>\n",
       "      <td>0.633208</td>\n",
       "      <td>-0.411502</td>\n",
       "      <td>-3.201592</td>\n",
       "      <td>-0.710612</td>\n",
       "      <td>0.786816</td>\n",
       "      <td>0.500979</td>\n",
       "      <td>-1.040048</td>\n",
       "      <td>-1.369170</td>\n",
       "      <td>0.987666</td>\n",
       "      <td>-0.681838</td>\n",
       "      <td>-0.331372</td>\n",
       "      <td>2.254289</td>\n",
       "      <td>-0.009330</td>\n",
       "      <td>2.007067</td>\n",
       "      <td>1.203750</td>\n",
       "      <td>-2.003928</td>\n",
       "      <td>-0.566088</td>\n",
       "      <td>0.223452</td>\n",
       "      <td>0.434202</td>\n",
       "      <td>-1.203766</td>\n",
       "      <td>-0.103490</td>\n",
       "      <td>0.441111</td>\n",
       "      <td>1.818458</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.231836</td>\n",
       "      <td>0.833236</td>\n",
       "      <td>-0.454226</td>\n",
       "      <td>-1.614694</td>\n",
       "      <td>0.159948</td>\n",
       "      <td>-0.150059</td>\n",
       "      <td>-1.570599</td>\n",
       "      <td>0.960839</td>\n",
       "      <td>0.102214</td>\n",
       "      <td>0.077236</td>\n",
       "      <td>0.852834</td>\n",
       "      <td>-1.265608</td>\n",
       "      <td>-3.219190</td>\n",
       "      <td>0.251194</td>\n",
       "      <td>0.215861</td>\n",
       "      <td>-0.009520</td>\n",
       "      <td>1.611203</td>\n",
       "      <td>1.679806</td>\n",
       "      <td>-0.008419</td>\n",
       "      <td>0.658384</td>\n",
       "      <td>-0.132437</td>\n",
       "      <td>-1.466823</td>\n",
       "      <td>-1.577080</td>\n",
       "      <td>-0.800346</td>\n",
       "      <td>1.960795</td>\n",
       "      <td>-4.042900</td>\n",
       "      <td>1.722143</td>\n",
       "      <td>-0.261888</td>\n",
       "      <td>-1.145005</td>\n",
       "      <td>-1.864582</td>\n",
       "      <td>-1.168967</td>\n",
       "      <td>1.385089</td>\n",
       "      <td>-0.353028</td>\n",
       "      <td>3.316150</td>\n",
       "      <td>-0.524087</td>\n",
       "      <td>-0.794327</td>\n",
       "      <td>3.936365</td>\n",
       "      <td>0.682989</td>\n",
       "      <td>-2.521211</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a8f910ea6075b6376af079055965ff68</td>\n",
       "      <td>-0.203933</td>\n",
       "      <td>-0.177252</td>\n",
       "      <td>0.368074</td>\n",
       "      <td>-0.701320</td>\n",
       "      <td>-1.104391</td>\n",
       "      <td>0.735760</td>\n",
       "      <td>0.894273</td>\n",
       "      <td>-1.375826</td>\n",
       "      <td>-5.144946</td>\n",
       "      <td>-2.048711</td>\n",
       "      <td>0.629773</td>\n",
       "      <td>-4.252669</td>\n",
       "      <td>-0.087420</td>\n",
       "      <td>-0.794367</td>\n",
       "      <td>-1.063963</td>\n",
       "      <td>0.115997</td>\n",
       "      <td>0.895180</td>\n",
       "      <td>3.184848</td>\n",
       "      <td>2.057840</td>\n",
       "      <td>-0.950821</td>\n",
       "      <td>0.961059</td>\n",
       "      <td>-1.837828</td>\n",
       "      <td>-0.437156</td>\n",
       "      <td>-0.828433</td>\n",
       "      <td>0.373747</td>\n",
       "      <td>-0.099787</td>\n",
       "      <td>-0.976280</td>\n",
       "      <td>-0.165921</td>\n",
       "      <td>3.297221</td>\n",
       "      <td>3.914132</td>\n",
       "      <td>-4.971376</td>\n",
       "      <td>-0.286520</td>\n",
       "      <td>-0.160133</td>\n",
       "      <td>-3.301453</td>\n",
       "      <td>-1.021032</td>\n",
       "      <td>-0.562744</td>\n",
       "      <td>0.574065</td>\n",
       "      <td>-0.368194</td>\n",
       "      <td>-0.507458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178099</td>\n",
       "      <td>-0.410396</td>\n",
       "      <td>-1.184236</td>\n",
       "      <td>1.681727</td>\n",
       "      <td>0.589606</td>\n",
       "      <td>0.064222</td>\n",
       "      <td>0.258885</td>\n",
       "      <td>0.560241</td>\n",
       "      <td>-1.545597</td>\n",
       "      <td>0.822283</td>\n",
       "      <td>1.518209</td>\n",
       "      <td>0.460143</td>\n",
       "      <td>0.822488</td>\n",
       "      <td>1.362718</td>\n",
       "      <td>0.218560</td>\n",
       "      <td>-1.038514</td>\n",
       "      <td>1.000763</td>\n",
       "      <td>-0.975878</td>\n",
       "      <td>-0.551268</td>\n",
       "      <td>-0.133044</td>\n",
       "      <td>-0.393092</td>\n",
       "      <td>1.236473</td>\n",
       "      <td>1.657100</td>\n",
       "      <td>0.833020</td>\n",
       "      <td>0.665379</td>\n",
       "      <td>-0.900025</td>\n",
       "      <td>0.291908</td>\n",
       "      <td>0.482727</td>\n",
       "      <td>0.552399</td>\n",
       "      <td>0.970496</td>\n",
       "      <td>-0.279168</td>\n",
       "      <td>1.544356</td>\n",
       "      <td>2.959727</td>\n",
       "      <td>1.641201</td>\n",
       "      <td>-0.130818</td>\n",
       "      <td>-0.264292</td>\n",
       "      <td>-0.748668</td>\n",
       "      <td>0.964218</td>\n",
       "      <td>0.087079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id   ...    target\n",
       "0  707b395ecdcbb4dc2eabea00e4d1b179   ...         0\n",
       "1  5880c03c6582a7b42248668e56b4bdec   ...         0\n",
       "2  4ccbcb3d13e5072ff1d9c61afe2c4f77   ...         1\n",
       "3  e350f17a357f12a1941f0837afb7eb8d   ...         0\n",
       "4  a8f910ea6075b6376af079055965ff68   ...         0\n",
       "\n",
       "[5 rows x 258 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import GraphicalLasso\n",
    "\n",
    "def get_mean_cov(x,y):\n",
    "    model = GraphicalLasso(max_iter=100)\n",
    "    ones = (y==1).astype(bool)\n",
    "    x2 = x[ones]\n",
    "    model.fit(x2)\n",
    "    p1 = model.precision_\n",
    "    m1 = model.location_\n",
    "    \n",
    "    onesb = (y==0).astype(bool)\n",
    "    x2b = x[onesb]\n",
    "    model.fit(x2b)\n",
    "    p2 = model.precision_\n",
    "    m2 = model.location_\n",
    "    \n",
    "    ms = np.stack([m1,m2])\n",
    "    ps = np.stack([p1,p2])\n",
    "    return ms,ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA scores CV = 0.96629\n"
     ]
    }
   ],
   "source": [
    "# INITIALIZE VARIABLES\n",
    "cols = [c for c in train.columns if c not in ['id', 'target']]\n",
    "cols.remove('wheezy-copper-turtle-magic')\n",
    "oof = np.zeros(len(train))\n",
    "preds = np.zeros(len(test))\n",
    "\n",
    "# BUILD 512 SEPARATE MODELS\n",
    "for i in range(512):\n",
    "    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n",
    "    train2 = train[train['wheezy-copper-turtle-magic']==i]\n",
    "    test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "    idx1 = train2.index; idx2 = test2.index\n",
    "    train2.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n",
    "    sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n",
    "    train3 = sel.transform(train2[cols])\n",
    "    test3 = sel.transform(test2[cols])\n",
    "    \n",
    "    # STRATIFIED K-FOLD\n",
    "    skf = StratifiedKFold(n_splits=51, random_state=42, shuffle=True)\n",
    "    for train_index, test_index in skf.split(train3, train2['target']):\n",
    "        \n",
    "        # MODEL AND PREDICT WITH QDA\n",
    "        clf = QuadraticDiscriminantAnalysis(reg_param=0.5)\n",
    "        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n",
    "        preds[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n",
    "       \n",
    "    #if i%64==0: print(i)\n",
    "        \n",
    "# PRINT CV AUC\n",
    "auc = roc_auc_score(train['target'],oof)\n",
    "print('QDA scores CV =',round(auc,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [22:27<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo Labeled KNN scores CV = 0.9483\n",
      "Pseudo Labeled QDA scores CV = 0.97031\n",
      "Pseudo Labeled SVC scores CV = 0.94611\n",
      "Pseudo Labeled GaussianMixture scores CV = 0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clfs = [KNeighborsClassifier(n_neighbors = 11, weights = 'distance', p = 2, metric = 'minkowski'),\n",
    "        QuadraticDiscriminantAnalysis(reg_param=0.6),\n",
    "        SVC(probability=True,kernel='poly',degree=4,gamma='auto')]\n",
    "names = ['KNN', 'QDA', 'SVC', 'GaussianMixture']\n",
    "\n",
    "\n",
    "# clfs = [QuadraticDiscriminantAnalysis(reg_param=0.6)]\n",
    "# names = ['QDA']\n",
    "\n",
    "\n",
    "# names = ['GaussianMixture']\n",
    "\n",
    "test['target'] = preds\n",
    "\n",
    "train_target = train['target'].copy()\n",
    "\n",
    "#flip label\n",
    "# train.loc[oof > 0.99, 'target'] = 1\n",
    "# train.loc[oof < 0.09, 'target'] = 0\n",
    "\n",
    "d = 0.01\n",
    "# for d in [0.011, 0.013, 0.015, 0.017, 0.019]:\n",
    "\n",
    "# INITIALIZE VARIABLES\n",
    "\n",
    "\n",
    "scores = [{'oof' : np.zeros(len(train)), 'preds' : np.zeros(len(test))} for clf in names]\n",
    "\n",
    "\n",
    "\n",
    "# BUILD 512 SEPARATE MODELS\n",
    "for k in tqdm(range(512)):\n",
    "    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n",
    "    train2 = train[train['wheezy-copper-turtle-magic']==k] \n",
    "    train2p = train2.copy(); idx1 = train2.index \n",
    "    test2 = test[test['wheezy-copper-turtle-magic']==k]\n",
    "\n",
    "    # ADD PSEUDO LABELED DATA\n",
    "    test2p = test2[ (test2['target']<=d) | (test2['target']>=1 - d) ].copy()\n",
    "    test2p.loc[ test2p['target']>=0.5, 'target' ] = 1\n",
    "    test2p.loc[ test2p['target']<0.5, 'target' ] = 0 \n",
    "    \n",
    "    \n",
    "    train2p = pd.concat([train2p,test2p],axis=0)\n",
    "    train2p.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n",
    "    sel = VarianceThreshold(threshold=2).fit(train2p[cols])     \n",
    "    train3p = sel.transform(train2p[cols])\n",
    "    train3 = sel.transform(train2[cols])\n",
    "    test3 = sel.transform(test2[cols])\n",
    "\n",
    "    # STRATIFIED K FOLD\n",
    "    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n",
    "    for train_index, test_index in skf.split(train3p, train2p['target']):\n",
    "        test_index3 = test_index[ test_index<len(train3) ] # ignore pseudo in oof\n",
    "\n",
    "        # MODEL AND PREDICT\n",
    "        for i in range(len(clfs)):\n",
    "            clfs[i].fit(train3p[train_index,:],train2p.loc[train_index]['target'])\n",
    "\n",
    "            scores[i]['oof'][idx1[test_index3]] = clfs[i].predict_proba(train3[test_index3,:])[:,1]\n",
    "            scores[i]['preds'][test2.index] += clfs[i].predict_proba(test3)[:,1] / skf.n_splits\n",
    "\n",
    "\n",
    "# PRINT CV AUC\n",
    "for i in range(len(scores)):\n",
    "    auc = roc_auc_score(train_target, scores[i]['oof'])\n",
    "    print('Pseudo Labeled {} scores CV = {}'.format(names[i], round(auc,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 80/512 [14:21<1:14:08, 10.30s/it]/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.176e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.555e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.570e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.423e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.333e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.472e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.461e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.320e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.363e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.552e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.448e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      " 73%|███████▎  | 375/512 [1:06:01<22:07,  9.69s/it]/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: -1.594e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: -1.658e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: -2.388e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: -1.820e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      " 90%|█████████ | 463/512 [1:21:16<08:41, 10.64s/it]/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.594e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.293e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.162e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.105e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.412e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.532e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.258e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.685e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.217e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.799e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.148e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.434e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.484e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.814e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.653e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.461e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.198e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.557e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.375e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      " 96%|█████████▋| 493/512 [1:26:55<03:35, 11.34s/it]/opt/conda/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:265: ConvergenceWarning: graphical_lasso: did not converge after 100 iteration: dual gap: 1.494e-04\n",
      "  % (max_iter, d_gap), ConvergenceWarning)\n",
      "100%|██████████| 512/512 [1:30:22<00:00, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA scores CV = 0.96629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# INITIALIZE VARIABLES\n",
    "# cols = [c for c in train.columns if c not in ['id', 'target']]\n",
    "# cols.remove('wheezy-copper-turtle-magic')\n",
    "# oof = np.zeros(len(train))\n",
    "# preds = np.zeros(len(test))\n",
    "\n",
    "gmm_ind = names.index('GaussianMixture')\n",
    "\n",
    "# BUILD 512 SEPARATE MODELS\n",
    "for i in tqdm(range(512)):\n",
    "    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n",
    "    train2 = train[train['wheezy-copper-turtle-magic']==i]\n",
    "    test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "    idx1 = train2.index; idx2 = test2.index\n",
    "    train2.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n",
    "    sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n",
    "    train3 = sel.transform(train2[cols])\n",
    "    test3 = sel.transform(test2[cols])\n",
    "    \n",
    "    # STRATIFIED K-FOLD\n",
    "    skf = StratifiedKFold(n_splits=51, random_state=42, shuffle=True)\n",
    "    for train_index, test_index in skf.split(train3, train2['target']):\n",
    "        \n",
    "        # MODEL AND PREDICT WITH QDA\n",
    "        ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values)\n",
    "        \n",
    "        gm = GaussianMixture(n_components=2, init_params='random', covariance_type='full', \n",
    "                             tol=0.001,reg_covar=0.001, max_iter=100, n_init=1,means_init=ms, \n",
    "                             precisions_init=ps)\n",
    "        gm.fit(np.concatenate([train3[train_index,:],test3],axis = 0))\n",
    "        scores[gmm_ind]['oof'][idx1[test_index]] = gm.predict_proba(train3[test_index,:])[:,0]\n",
    "        scores[gmm_ind]['preds'][idx2] += gm.predict_proba(test3)[:,0] / skf.n_splits\n",
    "\n",
    "        \n",
    "# PRINT CV AUC\n",
    "auc = roc_auc_score(train['target'],oof)\n",
    "print('QDA scores CV =',round(auc,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo Labeled KNN scores CV = 0.9483\n",
      "Pseudo Labeled QDA scores CV = 0.97031\n",
      "Pseudo Labeled SVC scores CV = 0.94611\n",
      "Pseudo Labeled GaussianMixture scores CV = 0.96916\n"
     ]
    }
   ],
   "source": [
    "# PRINT CV AUC\n",
    "for i in range(len(scores)):\n",
    "    auc = roc_auc_score(train_target, scores[i]['oof'])\n",
    "    print('Pseudo Labeled {} scores CV = {}'.format(names[i], round(auc,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo Labeled KNN scores CV = 0.9483\n",
      "Pseudo Labeled QDA scores CV = 0.97031\n",
      "Pseudo Labeled SVC scores CV = 0.94611\n",
      "Pseudo Labeled GaussianMixture scores CV = 0.96916\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(scores)):\n",
    "    auc = roc_auc_score(train_target, scores[i]['oof'])\n",
    "    print('Pseudo Labeled {} scores CV = {}'.format(names[i], round(auc,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "      <th>QDA</th>\n",
       "      <th>SVC</th>\n",
       "      <th>GaussianMixture</th>\n",
       "      <th>target</th>\n",
       "      <th>magic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.255933</td>\n",
       "      <td>3.815242e-13</td>\n",
       "      <td>0.024615</td>\n",
       "      <td>1.811959e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.175088</td>\n",
       "      <td>2.332591e-07</td>\n",
       "      <td>0.205148</td>\n",
       "      <td>1.101230e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.472646</td>\n",
       "      <td>9.999931e-01</td>\n",
       "      <td>0.910109</td>\n",
       "      <td>9.993703e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.186129</td>\n",
       "      <td>5.915015e-08</td>\n",
       "      <td>0.218772</td>\n",
       "      <td>6.670449e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.098714</td>\n",
       "      <td>8.352611e-13</td>\n",
       "      <td>0.070058</td>\n",
       "      <td>2.671360e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>497.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        KNN           QDA       SVC  GaussianMixture  target  magic\n",
       "0  0.255933  3.815242e-13  0.024615     1.811959e-07     0.0   99.0\n",
       "1  0.175088  2.332591e-07  0.205148     1.101230e-05     0.0   52.0\n",
       "2  0.472646  9.999931e-01  0.910109     9.993703e-01     1.0  230.0\n",
       "3  0.186129  5.915015e-08  0.218772     6.670449e-04     0.0   78.0\n",
       "4  0.098714  8.352611e-13  0.070058     2.671360e-09     0.0  497.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_oof = [scores[i]['oof'] for i in range(len(scores))]\n",
    "results_oof.append(np.array(train_target))\n",
    "results_oof.append(np.array(train['wheezy-copper-turtle-magic']))\n",
    "results_oof = np.array(results_oof).T\n",
    "columns = ['KNN', 'QDA', 'SVC', 'GaussianMixture', 'target', 'magic']\n",
    "# columns.append('target')\n",
    "stack_df = pd.DataFrame(results_oof, columns = columns) \n",
    "stack_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:14<00:00, 36.25it/s]\n"
     ]
    }
   ],
   "source": [
    "oof_final = np.zeros(len(train))\n",
    "preds_final = np.zeros(len(test))\n",
    "\n",
    "metrics_df = pd.DataFrame(columns=['magic', 'KNN', 'QDA', 'SVC', 'GaussianMixture'])\n",
    "for i in tqdm(range(512)):\n",
    "    line = [\n",
    "        i,\n",
    "        roc_auc_score(stack_df.loc[stack_df['magic']==i, 'target'],\n",
    "                     stack_df.loc[stack_df['magic']==i, 'KNN']),\n",
    "        roc_auc_score(stack_df.loc[stack_df['magic']==i, 'target'],\n",
    "                     stack_df.loc[stack_df['magic']==i, 'QDA']),\n",
    "        roc_auc_score(stack_df.loc[stack_df['magic']==i, 'target'],\n",
    "                     stack_df.loc[stack_df['magic']==i, 'SVC']),\n",
    "        roc_auc_score(stack_df.loc[stack_df['magic']==i, 'target'],\n",
    "                     stack_df.loc[stack_df['magic']==i, 'GaussianMixture'])\n",
    "    ]\n",
    "    metrics_df.loc[i] = line\n",
    "    \n",
    "    res = line[1:]\n",
    "    ind = np.array(res).argmax()\n",
    "    train2 = train[train['wheezy-copper-turtle-magic']==i]\n",
    "    test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "    idx1 = train2.index; idx2 = test2.index\n",
    "    \n",
    "    oof_final[idx1] = scores[ind]['oof'][idx1]\n",
    "    preds_final[idx2] = scores[ind]['preds'][idx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>magic</th>\n",
       "      <th>KNN</th>\n",
       "      <th>QDA</th>\n",
       "      <th>SVC</th>\n",
       "      <th>GaussianMixture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>207.0</td>\n",
       "      <td>0.940898</td>\n",
       "      <td>0.960895</td>\n",
       "      <td>0.941262</td>\n",
       "      <td>0.959465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     magic       KNN       QDA       SVC  GaussianMixture\n",
       "207  207.0  0.940898  0.960895  0.941262         0.959465"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df[metrics_df.magic == 207]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA scores CV = 0.96996\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(train['target'], oof_final)\n",
    "print('QDA scores CV =',round(auc,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_df['oof_final'] = oof_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "      <th>QDA</th>\n",
       "      <th>SVC</th>\n",
       "      <th>GaussianMixture</th>\n",
       "      <th>target</th>\n",
       "      <th>magic</th>\n",
       "      <th>oof_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.255933</td>\n",
       "      <td>3.815242e-13</td>\n",
       "      <td>0.024615</td>\n",
       "      <td>1.811959e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.815242e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.175088</td>\n",
       "      <td>2.332591e-07</td>\n",
       "      <td>0.205148</td>\n",
       "      <td>1.101230e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.101230e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.472646</td>\n",
       "      <td>9.999931e-01</td>\n",
       "      <td>0.910109</td>\n",
       "      <td>9.993703e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>9.999931e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.186129</td>\n",
       "      <td>5.915015e-08</td>\n",
       "      <td>0.218772</td>\n",
       "      <td>6.670449e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>5.915015e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.098714</td>\n",
       "      <td>8.352611e-13</td>\n",
       "      <td>0.070058</td>\n",
       "      <td>2.671360e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>8.352611e-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        KNN           QDA       SVC      ...       target  magic     oof_final\n",
       "0  0.255933  3.815242e-13  0.024615      ...          0.0   99.0  3.815242e-13\n",
       "1  0.175088  2.332591e-07  0.205148      ...          0.0   52.0  1.101230e-05\n",
       "2  0.472646  9.999931e-01  0.910109      ...          1.0  230.0  9.999931e-01\n",
       "3  0.186129  5.915015e-08  0.218772      ...          0.0   78.0  5.915015e-08\n",
       "4  0.098714  8.352611e-13  0.070058      ...          0.0  497.0  8.352611e-13\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo Labeled  scores CV = 0.97091\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "oof_stack = np.zeros(len(stack_df))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n",
    "for train_index, test_index in skf.split(stack_df, stack_df['target']):\n",
    "\n",
    "    clf = LogisticRegression(penalty='l1', C=0.01, verbose = 0, solver = 'liblinear')\n",
    "#     clf  = RandomForestClassifier(n_estimators = 100, max_depth = 7)\n",
    "    clf.fit(stack_df.loc[train_index].drop('target', axis = 1), stack_df.loc[train_index, 'target'])\n",
    "    oof_stack[test_index] = clf.predict_proba(stack_df.loc[test_index].drop('target', axis = 1))[:,1]\n",
    "\n",
    "\n",
    "\n",
    "auc = roc_auc_score(train_target, oof_stack)\n",
    "print('Pseudo Labeled {} scores CV = {}'.format('', round(auc,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo Labeled summ scores CV = 0.97041\n"
     ]
    }
   ],
   "source": [
    "# (scores[2]['oof'] * scores[0]['oof'] * (scores[1]['oof'] ** 20) ) + 500 * scores[1]['oof']\n",
    "auc = roc_auc_score(train['target'], ( 7000 * scores[1]['oof'] + 7000 * scores[3]['oof'] \n",
    "                                      +  2 * scores[2]['oof'] + 2 * scores[0]['oof']))\n",
    "print('Pseudo Labeled {} scores CV = {}'.format('summ', round(auc,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub = pd.read_csv('../input/sample_submission.csv')\n",
    "sub['target'] = (2 * scores[0]['preds'] + 7000 * scores[1]['preds'] \n",
    "                 + 2 * scores[2]['preds'] + 7000 * scores[3]['preds']) / 14004\n",
    "sub.to_csv('submission.csv',index=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(sub['target'],bins=100)\n",
    "plt.title('Final Test.csv predictions')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
